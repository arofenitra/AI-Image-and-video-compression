{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install compressai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF1CJGqpV2Bo",
        "outputId": "87ce733d-7885-456c-9386-9f871d52651b"
      },
      "id": "MF1CJGqpV2Bo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: compressai in /usr/local/lib/python3.11/dist-packages (1.2.6)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from compressai) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from compressai) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from compressai) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from compressai) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from compressai) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from compressai) (2.6.0+cu124)\n",
            "Requirement already satisfied: torch-geometric>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from compressai) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from compressai) (4.13.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from compressai) (0.21.0+cu124)\n",
            "Requirement already satisfied: pytorch-msssim in /usr/local/lib/python3.11/dist-packages (from compressai) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from compressai) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->compressai) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai) (3.11.15)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->compressai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->compressai) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->compressai) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->compressai) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b3199b9-5fdb-4b71-a988-ec9ccda935d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b3199b9-5fdb-4b71-a988-ec9ccda935d9",
        "outputId": "edd5521a-d850-4f39-c323-8b23375eacde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @amp.autocast(enabled=False)\n"
          ]
        }
      ],
      "source": [
        "import os, glob, argparse, math, itertools\n",
        "import torch, torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from compressai.zoo import bmshj2018_factorized, ssf2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3662a7b9-f2e4-48be-a597-aa70e223a57c",
      "metadata": {
        "id": "3662a7b9-f2e4-48be-a597-aa70e223a57c"
      },
      "outputs": [],
      "source": [
        "mot17_root = \"BoostTrack/data/MOT17/test\"\n",
        "sequence = \"MOT17-01-DPM\"\n",
        "img_folder = os.path.join(mot17_root, sequence, 'img1')\n",
        "output_folder = os.path.join('BoostTrack/data/MOT17-compressed', sequence)\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download = False"
      ],
      "metadata": {
        "id": "nsoF-NtpmgcX"
      },
      "id": "nsoF-NtpmgcX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "\n",
        "# Download MOT17 test data (Google Drive mirror)\n",
        "url = \"https://motchallenge.net/data/MOT17.zip\"  # MOT17-test.zip\n",
        "output = \"MOT17-test.zip\"\n",
        "\n",
        "if download:\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Unzip and organize folders\n",
        "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"BoostTrack/data/\")\n",
        "\n",
        "    # Clean up\n",
        "    os.remove(output)"
      ],
      "metadata": {
        "id": "k1rVeJOqYz8Q"
      },
      "id": "k1rVeJOqYz8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24d69cf-1c4d-47d0-b657-fc710d2d4036",
      "metadata": {
        "id": "f24d69cf-1c4d-47d0-b657-fc710d2d4036"
      },
      "outputs": [],
      "source": [
        "def pad_to_multiple(x, m):\n",
        "    \"\"\"\n",
        "    Reflect-pad so (H, W) is a multiple of m.\n",
        "    SSF / other video codecs need m = 128; most image codecs work with 64.\n",
        "    \"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    Hp, Wp = (m - H % m) % m, (m - W % m) % m\n",
        "    return F.pad(x, (0, Wp, 0, Hp), mode=\"reflect\"), (H, W)\n",
        "\n",
        "def bits_in(strings):\n",
        "    return sum(len(s) * 8 for s in flatten(strings))\n",
        "\n",
        "def flatten(l):\n",
        "    for el in l:\n",
        "        if isinstance(el, (list, tuple)):\n",
        "            yield from flatten(el)\n",
        "        else:\n",
        "            yield el"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0667778-dfd8-4e21-bd3f-36c82ee2bae8",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0667778-dfd8-4e21-bd3f-36c82ee2bae8",
        "outputId": "0e7a37f8-a507-4b2a-c8e5-cde0695b1dfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ScaleSpaceFlow(\n",
              "  (img_encoder): Encoder(\n",
              "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  )\n",
              "  (img_decoder): Decoder(\n",
              "    (0): ConvTranspose2d(192, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "  )\n",
              "  (img_hyperprior): Hyperprior(\n",
              "    (entropy_bottleneck): EntropyBottleneck(\n",
              "      (likelihood_lower_bound): LowerBound()\n",
              "    )\n",
              "    (hyper_encoder): HyperEncoder(\n",
              "      (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    )\n",
              "    (hyper_decoder_mean): HyperDecoder(\n",
              "      (0): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    )\n",
              "    (hyper_decoder_scale): HyperDecoderWithQReLU(\n",
              "      (deconv1): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (deconv2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (deconv3): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    )\n",
              "    (gaussian_conditional): GaussianConditional(\n",
              "      (likelihood_lower_bound): LowerBound()\n",
              "      (lower_bound_scale): LowerBound()\n",
              "    )\n",
              "  )\n",
              "  (res_encoder): Encoder(\n",
              "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  )\n",
              "  (res_decoder): Decoder(\n",
              "    (0): ConvTranspose2d(384, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "  )\n",
              "  (res_hyperprior): Hyperprior(\n",
              "    (entropy_bottleneck): EntropyBottleneck(\n",
              "      (likelihood_lower_bound): LowerBound()\n",
              "    )\n",
              "    (hyper_encoder): HyperEncoder(\n",
              "      (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    )\n",
              "    (hyper_decoder_mean): HyperDecoder(\n",
              "      (0): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    )\n",
              "    (hyper_decoder_scale): HyperDecoderWithQReLU(\n",
              "      (deconv1): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (deconv2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (deconv3): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    )\n",
              "    (gaussian_conditional): GaussianConditional(\n",
              "      (likelihood_lower_bound): LowerBound()\n",
              "      (lower_bound_scale): LowerBound()\n",
              "    )\n",
              "  )\n",
              "  (motion_encoder): Encoder(\n",
              "    (0): Conv2d(6, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  )\n",
              "  (motion_decoder): Decoder(\n",
              "    (0): ConvTranspose2d(192, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "  )\n",
              "  (motion_hyperprior): Hyperprior(\n",
              "    (entropy_bottleneck): EntropyBottleneck(\n",
              "      (likelihood_lower_bound): LowerBound()\n",
              "    )\n",
              "    (hyper_encoder): HyperEncoder(\n",
              "      (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    )\n",
              "    (hyper_decoder_mean): HyperDecoder(\n",
              "      (0): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    )\n",
              "    (hyper_decoder_scale): HyperDecoderWithQReLU(\n",
              "      (deconv1): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (deconv2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "      (deconv3): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    )\n",
              "    (gaussian_conditional): GaussianConditional(\n",
              "      (likelihood_lower_bound): LowerBound()\n",
              "      (lower_bound_scale): LowerBound()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quality = 1\n",
        "model = ssf2020(quality=quality, metric='mse', pretrained=True).to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8087dc6-298f-420c-88c4-5c93d9ef2f49",
      "metadata": {
        "id": "f8087dc6-298f-420c-88c4-5c93d9ef2f49"
      },
      "outputs": [],
      "source": [
        "video_codec = True\n",
        "PAD_M = 128\n",
        "to_tensor = transforms.ToTensor()\n",
        "frames = sorted(glob.glob(os.path.join(img_folder, \"*.jpg\"))\n",
        "                + glob.glob(os.path.join(img_folder, \"*.png\")))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame_paths = frames[::10]"
      ],
      "metadata": {
        "id": "dQw2oEYUWx0H"
      },
      "id": "dQw2oEYUWx0H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MR2_5_P4YRXl",
        "outputId": "47e2eeab-5851-47a3-9455-d23985dc9580"
      },
      "id": "MR2_5_P4YRXl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BoostTrack/data/MOT17/test/MOT17-01-DPM/img1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df5759ff-9442-4c75-a466-3ffe8b2e42f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df5759ff-9442-4c75-a466-3ffe8b2e42f4",
        "outputId": "dd9851b3-b866-4bcf-e39c-7dc3521b8351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading frames: 100%|██████████| 45/45 [00:03<00:00, 13.96it/s]\n"
          ]
        }
      ],
      "source": [
        "total_bits, orig_hws = 0, []\n",
        "strings_list, shapes_list = [], []\n",
        "\n",
        "clip = []\n",
        "for fp in tqdm(frame_paths, desc=\"Loading frames\"):\n",
        "    img = Image.open(fp).convert(\"RGB\")\n",
        "    x   = to_tensor(img).unsqueeze(0).to(device)\n",
        "    x, hw = pad_to_multiple(x, PAD_M)\n",
        "    clip.append(x)\n",
        "    orig_hws.append(hw)\n",
        "\n",
        "with torch.no_grad():\n",
        "    strings_list, shapes_list = model.compress(clip)\n",
        "\n",
        "for i, (s, sh, hw) in enumerate(zip(strings_list, shapes_list, orig_hws)):\n",
        "    torch.save({\"strings\": s, \"shape\": sh, \"orig_hw\": hw},\n",
        "                os.path.join(output_folder, f\"{i:06d}.pth\"))\n",
        "    total_bits += bits_in(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef959180-e1ba-4572-b765-0394a9d4be7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef959180-e1ba-4572-b765-0394a9d4be7b",
        "outputId": "5f915272-994b-456d-8d33-e738f4912754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compressed → BoostTrack/data/MOT17-compressed/MOT17-01-DPM\n",
            "Total size : 19.9 kB\n"
          ]
        }
      ],
      "source": [
        "print(f\"Compressed → {output_folder}\")\n",
        "print(f\"Total size : {total_bits/8/1024:.1f} kB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2a7a0e-d22a-4e49-92e2-99e848c6bae1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2a7a0e-d22a-4e49-92e2-99e848c6bae1",
        "outputId": "8fb879b2-48cc-4c0c-fa7b-93626433e283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring:   0%|          | 0/45 [00:00<?, ?it/s]<ipython-input-13-a67693246ea9>:18: UserWarning: Using a target size (torch.Size([3, 1080, 1920])) that is different to the input size (torch.Size([1, 3, 1080, 1920])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n",
            "Scoring: 100%|██████████| 45/45 [00:02<00:00, 19.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sequence average →  0.0017 bpp   |   23.08 dB PSNR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "psnr_sum = 0.0\n",
        "n_pixels = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    if video_codec:\n",
        "        recon_clip = model.decompress(strings_list, shapes_list)\n",
        "\n",
        "    for i, fp in enumerate(tqdm(frame_paths, desc=\"Scoring\")):\n",
        "        if video_codec:\n",
        "            x_hat = recon_clip[i]\n",
        "        else:\n",
        "            x_hat = model.decompress([strings_list[i]], [shapes_list[i]])[0]\n",
        "\n",
        "        H, W  = orig_hws[i]\n",
        "        x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "\n",
        "        x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
        "        mse   = F.mse_loss(x_hat, x_ref)\n",
        "        psnr  = -10 * torch.log10(mse)\n",
        "\n",
        "        psnr_sum += psnr.item()\n",
        "        n_pixels += H * W\n",
        "\n",
        "avg_psnr = psnr_sum / len(frame_paths)\n",
        "bpp      = total_bits / n_pixels\n",
        "\n",
        "print(f\"\\nSequence average →  {bpp:.4f} bpp   |   {avg_psnr:.2f} dB PSNR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73952b3f-0ac1-4dd6-92a4-8068d59de8ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73952b3f-0ac1-4dd6-92a4-8068d59de8ba",
        "outputId": "0d7d9ff7-f11f-4dc3-d8e6-aa805fa2aa39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-4c1591c1ed9d>:7: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(_np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "import os, glob, math, itertools, shutil, gc\n",
        "import torch, torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import numpy as _np\n",
        "if not hasattr(_np, \"object\"):\n",
        "    _np.object = object\n",
        "\n",
        "from torchvision import transforms\n",
        "from compressai.zoo import bmshj2018_factorized, ssf2020\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734023fa-09ba-457e-88be-f7bc525e5d41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "734023fa-09ba-457e-88be-f7bc525e5d41",
        "outputId": "e142a2dd-9af7-45b0-ccbe-4f46424abe47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "mot17_root = \"BoostTrack/data/MOT17/test\"\n",
        "out_root   = \"BoostTrack/data/MOT17_processed/test\"\n",
        "os.makedirs(out_root, exist_ok=True)\n",
        "\n",
        "codec_name = \"ssf2020\"\n",
        "quality    = 1\n",
        "\n",
        "# Set GOP_SIZE=None to encode an entire sequence in one call.\n",
        "GOP_SIZE   = 1 if codec_name.startswith(\"ssf\") else None\n",
        "\n",
        "device     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7347044-f2c6-4c74-bb29-4b8632ad938f",
      "metadata": {
        "id": "f7347044-f2c6-4c74-bb29-4b8632ad938f"
      },
      "outputs": [],
      "source": [
        "def pad_to_multiple(x, m):\n",
        "    \"\"\"Reflect-pad so (H, W) is divisible by *m*.\"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    Hp, Wp = (m - H % m) % m, (m - W % m) % m\n",
        "    return F.pad(x, (0, Wp, 0, Hp), mode=\"reflect\"), (H, W)\n",
        "\n",
        "def flatten(nested):\n",
        "    for el in nested:\n",
        "        if isinstance(el, (list, tuple)):\n",
        "            yield from flatten(el)\n",
        "        else:\n",
        "            yield el\n",
        "\n",
        "def bits_in(strings):\n",
        "    return sum(len(s) * 8 for s in flatten(strings))\n",
        "\n",
        "to_tensor = transforms.ToTensor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02786c36-a927-4c3d-9e86-da54715b0d63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02786c36-a927-4c3d-9e86-da54715b0d63",
        "outputId": "00857f53-b385-4aac-b6e5-7182b5bd9846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ssf2020-Q1  (video=True)\n"
          ]
        }
      ],
      "source": [
        "if codec_name == \"bmshj2018_factorized\":\n",
        "    model      = bmshj2018_factorized(quality=quality, pretrained=True).eval().to(device)\n",
        "    video_code = False\n",
        "    PAD_M      = 64\n",
        "elif codec_name == \"ssf2020\":\n",
        "    model      = ssf2020(quality=quality, pretrained=True).eval().to(device)\n",
        "    video_code = True\n",
        "    PAD_M      = 128         # SSF ↓16, hyper-prior ↑8 → needs /128\n",
        "else:\n",
        "    raise ValueError(f\"Unknown codec {codec_name}\")\n",
        "\n",
        "print(f\"Loaded {codec_name}-Q{quality}  (video={video_code})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329286bd-cf2f-4a46-b31d-6b684cba3ac4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "329286bd-cf2f-4a46-b31d-6b684cba3ac4",
        "outputId": "d5ccf810-903e-403a-d303-a9f3efd0a913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21 sequences:\n",
            " • MOT17-01-DPM\n",
            " • MOT17-01-FRCNN\n",
            " • MOT17-01-SDP\n",
            " • MOT17-03-DPM\n",
            " • MOT17-03-FRCNN\n",
            " • MOT17-03-SDP\n",
            " • MOT17-06-DPM\n",
            " • MOT17-06-FRCNN\n",
            " • MOT17-06-SDP\n",
            " • MOT17-07-DPM\n",
            " • MOT17-07-FRCNN\n",
            " • MOT17-07-SDP\n",
            " • MOT17-08-DPM\n",
            " • MOT17-08-FRCNN\n",
            " • MOT17-08-SDP\n",
            " • MOT17-12-DPM\n",
            " • MOT17-12-FRCNN\n",
            " • MOT17-12-SDP\n",
            " • MOT17-14-DPM\n",
            " • MOT17-14-FRCNN\n",
            " • MOT17-14-SDP\n"
          ]
        }
      ],
      "source": [
        "sequences = [d for d in os.listdir(mot17_root)\n",
        "             if os.path.isdir(os.path.join(mot17_root, d, \"img1\"))]\n",
        "sequences.sort()\n",
        "print(\"Found\", len(sequences), \"sequences:\")\n",
        "for s in sequences: print(\" •\", s)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "jNS3j9QLjsJb"
      },
      "id": "jNS3j9QLjsJb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49266158-2ab5-4c9b-ab6b-abe16fc3c5e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49266158-2ab5-4c9b-ab6b-abe16fc3c5e9",
        "outputId": "0ad5f919-a36d-4aa8-d24c-595e3d1eb12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MOT17-01-DPM ===\n",
            "Frames: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 1080, 1920])) that is different to the input size (torch.Size([1, 3, 1080, 1920])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 0.0751 bpp   |   29.13 dB PSNR\n",
            "\n",
            "=== MOT17-01-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0751 bpp   |   27.92 dB PSNR\n",
            "\n",
            "=== MOT17-01-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0751 bpp   |   28.51 dB PSNR\n",
            "\n",
            "=== MOT17-03-DPM ===\n",
            "Frames: 15\n",
            "→ 0.0630 bpp   |   32.29 dB PSNR\n",
            "\n",
            "=== MOT17-03-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0630 bpp   |   31.99 dB PSNR\n",
            "\n",
            "=== MOT17-03-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0630 bpp   |   31.34 dB PSNR\n",
            "\n",
            "=== MOT17-06-DPM ===\n",
            "Frames: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 480, 640])) that is different to the input size (torch.Size([1, 3, 480, 640])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 0.0622 bpp   |   32.18 dB PSNR\n",
            "\n",
            "=== MOT17-06-FRCNN ===\n",
            "Frames: 16\n",
            "→ 0.0622 bpp   |   32.18 dB PSNR\n",
            "\n",
            "=== MOT17-06-SDP ===\n",
            "Frames: 16\n",
            "→ 0.0622 bpp   |   32.18 dB PSNR\n",
            "\n",
            "=== MOT17-07-DPM ===\n",
            "Frames: 16\n",
            "→ 0.0748 bpp   |   29.35 dB PSNR\n",
            "\n",
            "=== MOT17-07-FRCNN ===\n",
            "Frames: 16\n",
            "→ 0.0748 bpp   |   30.24 dB PSNR\n",
            "\n",
            "=== MOT17-07-SDP ===\n",
            "Frames: 16\n",
            "→ 0.0748 bpp   |   30.74 dB PSNR\n",
            "\n",
            "=== MOT17-08-DPM ===\n",
            "Frames: 16\n",
            "→ 0.1234 bpp   |   28.92 dB PSNR\n",
            "\n",
            "=== MOT17-08-FRCNN ===\n",
            "Frames: 16\n",
            "→ 0.1234 bpp   |   28.52 dB PSNR\n",
            "\n",
            "=== MOT17-08-SDP ===\n",
            "Frames: 16\n",
            "→ 0.1234 bpp   |   28.92 dB PSNR\n",
            "\n",
            "=== MOT17-12-DPM ===\n",
            "Frames: 15\n",
            "→ 0.0567 bpp   |   32.63 dB PSNR\n",
            "\n",
            "=== MOT17-12-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0567 bpp   |   33.85 dB PSNR\n",
            "\n",
            "=== MOT17-12-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0567 bpp   |   32.63 dB PSNR\n",
            "\n",
            "=== MOT17-14-DPM ===\n",
            "Frames: 15\n",
            "→ 0.0783 bpp   |   32.23 dB PSNR\n",
            "\n",
            "=== MOT17-14-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0783 bpp   |   31.09 dB PSNR\n",
            "\n",
            "=== MOT17-14-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0783 bpp   |   32.23 dB PSNR\n"
          ]
        }
      ],
      "source": [
        "summary = []          # will collect (seq, frames, bpp, psnr)\n",
        "for seq in sequences:\n",
        "    print(f\"\\n=== {seq} ===\")\n",
        "    img_dir = os.path.join(mot17_root, seq, \"img1\")\n",
        "    out_dir = os.path.join(out_root,   seq)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    out_dir_img1 = os.path.join(out_root, seq, \"img1\")\n",
        "    os.makedirs(out_dir_img1, exist_ok=True)\n",
        "\n",
        "    det_src = os.path.join(mot17_root, seq, \"det\")\n",
        "    det_dst = os.path.join(out_root,   seq, \"det\")\n",
        "    if not os.path.exists(det_dst):\n",
        "        shutil.copytree(det_src, det_dst)\n",
        "    shutil.copy(os.path.join(mot17_root, seq, \"seqinfo.ini\"),\n",
        "                os.path.join(out_root,   seq, \"seqinfo.ini\"))\n",
        "\n",
        "    frame_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
        "                         glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    frame_paths = frame_paths[::len(frame_paths)//15]\n",
        "    n_frames = len(frame_paths)\n",
        "    print(\"Frames:\", n_frames)\n",
        "\n",
        "    total_bits, psnr_sum, n_pixels = 0, 0.0, 0\n",
        "\n",
        "    if video_code:\n",
        "        # ── process in chunks (=GOPs) to control memory\n",
        "        gop = n_frames if GOP_SIZE is None else GOP_SIZE\n",
        "        for g in range(0, n_frames, gop):\n",
        "            end = min(g + gop, n_frames)\n",
        "            clip, orig_hws = [], []\n",
        "            for fp in frame_paths[g:end]:\n",
        "                img = Image.open(fp).convert(\"RGB\")\n",
        "                x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "                clip.append(x); orig_hws.append(hw)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                strings, shapes = model.compress(clip)\n",
        "\n",
        "            # save + metrics\n",
        "            recon = model.decompress(strings, shapes)\n",
        "            for i, (st, sh, hw, x_hat, fp) in enumerate(zip(\n",
        "                    strings, shapes, orig_hws, recon, frame_paths[g:end])):\n",
        "                idx = g + i\n",
        "                # torch.save({\"strings\": st, \"shape\": sh, \"orig_hw\": hw},\n",
        "                #            os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "                total_bits += bits_in(st)\n",
        "\n",
        "                H, W = hw\n",
        "                x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "                x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
        "                mse   = F.mse_loss(x_hat, x_ref)\n",
        "                psnr  = -10 * torch.log10(mse)\n",
        "                psnr_sum += psnr.item()\n",
        "                n_pixels += H * W\n",
        "\n",
        "                rgb8 = (x_hat.squeeze(0).permute(1, 2, 0).clamp_(0, 1).cpu().detach().numpy() * 255).round().astype('uint8')\n",
        "\n",
        "                # write JPEG with MOT naming\n",
        "                cv2.imwrite(os.path.join(out_dir_img1, f\"{idx+1:06d}.jpg\"),\n",
        "                            cv2.cvtColor(rgb8, cv2.COLOR_RGB2BGR),\n",
        "                            [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "\n",
        "            # free GPU mem each GOP\n",
        "            del clip, recon, strings, shapes\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    else:  # ── image codec\n",
        "        for idx, fp in enumerate(tqdm(frame_paths, desc=\"Compressing\")):\n",
        "            img = Image.open(fp).convert(\"RGB\")\n",
        "            x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "            with torch.no_grad():\n",
        "                out = model.compress(x)\n",
        "                x_hat = model.decompress(out[\"strings\"], out[\"shape\"])[0]\n",
        "\n",
        "            torch.save({\"strings\": out[\"strings\"], \"shape\": out[\"shape\"], \"orig_hw\": hw},\n",
        "                       os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "            total_bits += bits_in(out[\"strings\"])\n",
        "\n",
        "            H, W  = hw\n",
        "            x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "            mse   = F.mse_loss(x_hat, to_tensor(img).to(device))\n",
        "            psnr  = -10 * torch.log10(mse)\n",
        "            psnr_sum += psnr.item()\n",
        "            n_pixels += H * W\n",
        "\n",
        "    bpp  = total_bits / n_pixels\n",
        "    psnr = psnr_sum / n_frames\n",
        "    summary.append((seq, n_frames, bpp, psnr))\n",
        "    print(f\"→ {bpp:.4f} bpp   |   {psnr:.2f} dB PSNR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8752732-1af3-434b-b6a6-02baca9301d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8752732-1af3-434b-b6a6-02baca9301d2",
        "outputId": "6849bcc2-f3f3-4872-aa55-717d52ec0422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===========  SUMMARY  ===========\n",
            "Sequence              Frames   BPP     PSNR\n",
            "MOT17-01-DPM              15   0.0751    29.13\n",
            "MOT17-01-FRCNN            15   0.0751    27.92\n",
            "MOT17-01-SDP              15   0.0751    28.51\n",
            "MOT17-03-DPM              15   0.0630    32.29\n",
            "MOT17-03-FRCNN            15   0.0630    31.99\n",
            "MOT17-03-SDP              15   0.0630    31.34\n",
            "MOT17-06-DPM              16   0.0622    32.18\n",
            "MOT17-06-FRCNN            16   0.0622    32.18\n",
            "MOT17-06-SDP              16   0.0622    32.18\n",
            "MOT17-07-DPM              16   0.0748    29.35\n",
            "MOT17-07-FRCNN            16   0.0748    30.24\n",
            "MOT17-07-SDP              16   0.0748    30.74\n",
            "MOT17-08-DPM              16   0.1234    28.92\n",
            "MOT17-08-FRCNN            16   0.1234    28.52\n",
            "MOT17-08-SDP              16   0.1234    28.92\n",
            "MOT17-12-DPM              15   0.0567    32.63\n",
            "MOT17-12-FRCNN            15   0.0567    33.85\n",
            "MOT17-12-SDP              15   0.0567    32.63\n",
            "MOT17-14-DPM              15   0.0783    32.23\n",
            "MOT17-14-FRCNN            15   0.0783    31.09\n",
            "MOT17-14-SDP              15   0.0783    32.23\n",
            "----------------------------------------------\n",
            "Overall                       0.0765    30.89\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n===========  SUMMARY  ===========\")\n",
        "print(f\"{'Sequence':20}  Frames   BPP     PSNR\")\n",
        "for seq, n, bpp, psnr in summary:\n",
        "    print(f\"{seq:20}  {n:6d}   {bpp:5.4f}   {psnr:6.2f}\")\n",
        "overall_bpp  = sum(bpp*n for (_,n,bpp,_) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "overall_psnr = sum(psnr*n for (_,n,_,psnr) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "print(\"----------------------------------------------\")\n",
        "print(f\"{'Overall':20}          {overall_bpp:5.4f}   {overall_psnr:6.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5b23a2-44ca-406e-86e1-b9826a3379c8",
      "metadata": {
        "id": "0d5b23a2-44ca-406e-86e1-b9826a3379c8"
      },
      "outputs": [],
      "source": [
        "mot17_root = \"BoostTrack/data/MOT17/train\"\n",
        "out_root   = \"BoostTrack/data/MOT17_processed/train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21ff6e1-dc3c-4563-b80d-25ece9499997",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b21ff6e1-dc3c-4563-b80d-25ece9499997",
        "outputId": "2aa6cd57-db4b-4f02-c6e6-415976f1eb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21 sequences:\n",
            " • MOT17-02-DPM\n",
            " • MOT17-02-FRCNN\n",
            " • MOT17-02-SDP\n",
            " • MOT17-04-DPM\n",
            " • MOT17-04-FRCNN\n",
            " • MOT17-04-SDP\n",
            " • MOT17-05-DPM\n",
            " • MOT17-05-FRCNN\n",
            " • MOT17-05-SDP\n",
            " • MOT17-09-DPM\n",
            " • MOT17-09-FRCNN\n",
            " • MOT17-09-SDP\n",
            " • MOT17-10-DPM\n",
            " • MOT17-10-FRCNN\n",
            " • MOT17-10-SDP\n",
            " • MOT17-11-DPM\n",
            " • MOT17-11-FRCNN\n",
            " • MOT17-11-SDP\n",
            " • MOT17-13-DPM\n",
            " • MOT17-13-FRCNN\n",
            " • MOT17-13-SDP\n"
          ]
        }
      ],
      "source": [
        "sequences = [d for d in os.listdir(mot17_root)\n",
        "             if os.path.isdir(os.path.join(mot17_root, d, \"img1\"))]\n",
        "sequences.sort()\n",
        "print(\"Found\", len(sequences), \"sequences:\")\n",
        "for s in sequences: print(\" •\", s)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QR_fHdF6mMcA"
      },
      "id": "QR_fHdF6mMcA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bb87e34-4e8d-473f-bcf1-407248ea8217",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bb87e34-4e8d-473f-bcf1-407248ea8217",
        "outputId": "02d6a416-0a8a-47ab-9b72-4d5c7276c640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MOT17-02-DPM ===\n",
            "Frames: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 1080, 1920])) that is different to the input size (torch.Size([1, 3, 1080, 1920])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 0.0843 bpp   |   29.51 dB PSNR\n",
            "\n",
            "=== MOT17-02-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0843 bpp   |   30.66 dB PSNR\n",
            "\n",
            "=== MOT17-02-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0843 bpp   |   30.01 dB PSNR\n",
            "\n",
            "=== MOT17-04-DPM ===\n",
            "Frames: 15\n",
            "→ 0.0528 bpp   |   33.58 dB PSNR\n",
            "\n",
            "=== MOT17-04-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0528 bpp   |   33.07 dB PSNR\n",
            "\n",
            "=== MOT17-04-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0528 bpp   |   33.00 dB PSNR\n",
            "\n",
            "=== MOT17-05-DPM ===\n",
            "Frames: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 480, 640])) that is different to the input size (torch.Size([1, 3, 480, 640])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 0.0828 bpp   |   31.28 dB PSNR\n",
            "\n",
            "=== MOT17-05-FRCNN ===\n",
            "Frames: 16\n",
            "→ 0.0828 bpp   |   30.47 dB PSNR\n",
            "\n",
            "=== MOT17-05-SDP ===\n",
            "Frames: 16\n",
            "→ 0.0828 bpp   |   31.28 dB PSNR\n",
            "\n",
            "=== MOT17-09-DPM ===\n",
            "Frames: 15\n",
            "→ 0.0803 bpp   |   30.56 dB PSNR\n",
            "\n",
            "=== MOT17-09-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0803 bpp   |   30.74 dB PSNR\n",
            "\n",
            "=== MOT17-09-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0803 bpp   |   28.55 dB PSNR\n",
            "\n",
            "=== MOT17-10-DPM ===\n",
            "Frames: 16\n",
            "→ 0.0533 bpp   |   31.79 dB PSNR\n",
            "\n",
            "=== MOT17-10-FRCNN ===\n",
            "Frames: 16\n",
            "→ 0.0533 bpp   |   32.94 dB PSNR\n",
            "\n",
            "=== MOT17-10-SDP ===\n",
            "Frames: 16\n",
            "→ 0.0533 bpp   |   33.44 dB PSNR\n",
            "\n",
            "=== MOT17-11-DPM ===\n",
            "Frames: 15\n",
            "→ 0.0630 bpp   |   33.28 dB PSNR\n",
            "\n",
            "=== MOT17-11-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0630 bpp   |   31.60 dB PSNR\n",
            "\n",
            "=== MOT17-11-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0630 bpp   |   33.28 dB PSNR\n",
            "\n",
            "=== MOT17-13-DPM ===\n",
            "Frames: 15\n",
            "→ 0.0672 bpp   |   33.25 dB PSNR\n",
            "\n",
            "=== MOT17-13-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.0672 bpp   |   31.15 dB PSNR\n",
            "\n",
            "=== MOT17-13-SDP ===\n",
            "Frames: 15\n",
            "→ 0.0672 bpp   |   33.25 dB PSNR\n"
          ]
        }
      ],
      "source": [
        "summary = []          # will collect (seq, frames, bpp, psnr)\n",
        "for seq in sequences:\n",
        "    print(f\"\\n=== {seq} ===\")\n",
        "    img_dir = os.path.join(mot17_root, seq, \"img1\")\n",
        "    out_dir = os.path.join(out_root,   seq)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    out_dir_img1 = os.path.join(out_root, seq, \"img1\")\n",
        "    os.makedirs(out_dir_img1, exist_ok=True)\n",
        "\n",
        "    det_src = os.path.join(mot17_root, seq, \"det\")\n",
        "    det_dst = os.path.join(out_root,   seq, \"det\")\n",
        "    if not os.path.exists(det_dst):\n",
        "        shutil.copytree(det_src, det_dst)\n",
        "    shutil.copy(os.path.join(mot17_root, seq, \"seqinfo.ini\"),\n",
        "                os.path.join(out_root,   seq, \"seqinfo.ini\"))\n",
        "\n",
        "    frame_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
        "                         glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    frame_paths = frame_paths[::len(frame_paths)//15]\n",
        "    n_frames = len(frame_paths)\n",
        "    print(\"Frames:\", n_frames)\n",
        "\n",
        "    total_bits, psnr_sum, n_pixels = 0, 0.0, 0\n",
        "\n",
        "    if video_code:\n",
        "        # ── process in chunks (=GOPs) to control memory\n",
        "        gop = n_frames if GOP_SIZE is None else GOP_SIZE\n",
        "        for g in range(0, n_frames, gop):\n",
        "            end = min(g + gop, n_frames)\n",
        "            clip, orig_hws = [], []\n",
        "            for fp in frame_paths[g:end]:\n",
        "                img = Image.open(fp).convert(\"RGB\")\n",
        "                x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "                clip.append(x); orig_hws.append(hw)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                strings, shapes = model.compress(clip)\n",
        "\n",
        "            # save + metrics\n",
        "            recon = model.decompress(strings, shapes)\n",
        "            for i, (st, sh, hw, x_hat, fp) in enumerate(zip(\n",
        "                    strings, shapes, orig_hws, recon, frame_paths[g:end])):\n",
        "                idx = g + i\n",
        "                # torch.save({\"strings\": st, \"shape\": sh, \"orig_hw\": hw},\n",
        "                #            os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "                total_bits += bits_in(st)\n",
        "\n",
        "                H, W = hw\n",
        "                x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "                x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
        "                mse   = F.mse_loss(x_hat, x_ref)\n",
        "                psnr  = -10 * torch.log10(mse)\n",
        "                psnr_sum += psnr.item()\n",
        "                n_pixels += H * W\n",
        "\n",
        "                rgb8 = (x_hat.squeeze(0).permute(1, 2, 0).clamp_(0, 1).cpu().detach().numpy() * 255).round().astype('uint8')\n",
        "\n",
        "                # write JPEG with MOT naming\n",
        "                cv2.imwrite(os.path.join(out_dir_img1, f\"{idx+1:06d}.jpg\"),\n",
        "                            cv2.cvtColor(rgb8, cv2.COLOR_RGB2BGR),\n",
        "                            [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "\n",
        "            # free GPU mem each GOP\n",
        "            del clip, recon, strings, shapes\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    else:  # ── image codec\n",
        "        for idx, fp in enumerate(tqdm(frame_paths, desc=\"Compressing\")):\n",
        "            img = Image.open(fp).convert(\"RGB\")\n",
        "            x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "            with torch.no_grad():\n",
        "                out = model.compress(x)\n",
        "                x_hat = model.decompress(out[\"strings\"], out[\"shape\"])[0]\n",
        "\n",
        "            torch.save({\"strings\": out[\"strings\"], \"shape\": out[\"shape\"], \"orig_hw\": hw},\n",
        "                       os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "            total_bits += bits_in(out[\"strings\"])\n",
        "\n",
        "            H, W  = hw\n",
        "            x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "            mse   = F.mse_loss(x_hat, to_tensor(img).to(device))\n",
        "            psnr  = -10 * torch.log10(mse)\n",
        "            psnr_sum += psnr.item()\n",
        "            n_pixels += H * W\n",
        "\n",
        "    bpp  = total_bits / n_pixels\n",
        "    psnr = psnr_sum / n_frames\n",
        "    summary.append((seq, n_frames, bpp, psnr))\n",
        "    print(f\"→ {bpp:.4f} bpp   |   {psnr:.2f} dB PSNR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "800b5191-9a91-4fe2-b56d-d9e97824a1d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "800b5191-9a91-4fe2-b56d-d9e97824a1d5",
        "outputId": "6270593e-5042-49ee-fa17-74e8542bc2d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===========  SUMMARY  ===========\n",
            "Sequence              Frames   BPP     PSNR\n",
            "MOT17-02-DPM              15   0.0843    29.51\n",
            "MOT17-02-FRCNN            15   0.0843    30.66\n",
            "MOT17-02-SDP              15   0.0843    30.01\n",
            "MOT17-04-DPM              15   0.0528    33.58\n",
            "MOT17-04-FRCNN            15   0.0528    33.07\n",
            "MOT17-04-SDP              15   0.0528    33.00\n",
            "MOT17-05-DPM              16   0.0828    31.28\n",
            "MOT17-05-FRCNN            16   0.0828    30.47\n",
            "MOT17-05-SDP              16   0.0828    31.28\n",
            "MOT17-09-DPM              15   0.0803    30.56\n",
            "MOT17-09-FRCNN            15   0.0803    30.74\n",
            "MOT17-09-SDP              15   0.0803    28.55\n",
            "MOT17-10-DPM              16   0.0533    31.79\n",
            "MOT17-10-FRCNN            16   0.0533    32.94\n",
            "MOT17-10-SDP              16   0.0533    33.44\n",
            "MOT17-11-DPM              15   0.0630    33.28\n",
            "MOT17-11-FRCNN            15   0.0630    31.60\n",
            "MOT17-11-SDP              15   0.0630    33.28\n",
            "MOT17-13-DPM              15   0.0672    33.25\n",
            "MOT17-13-FRCNN            15   0.0672    31.15\n",
            "MOT17-13-SDP              15   0.0672    33.25\n",
            "----------------------------------------------\n",
            "Overall                       0.0691    31.75\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n===========  SUMMARY  ===========\")\n",
        "print(f\"{'Sequence':20}  Frames   BPP     PSNR\")\n",
        "for seq, n, bpp, psnr in summary:\n",
        "    print(f\"{seq:20}  {n:6d}   {bpp:5.4f}   {psnr:6.2f}\")\n",
        "overall_bpp  = sum(bpp*n for (_,n,bpp,_) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "overall_psnr = sum(psnr*n for (_,n,_,psnr) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "print(\"----------------------------------------------\")\n",
        "print(f\"{'Overall':20}          {overall_bpp:5.4f}   {overall_psnr:6.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66936367-0b37-4d70-81b4-0e30fc55b07e",
      "metadata": {
        "id": "66936367-0b37-4d70-81b4-0e30fc55b07e"
      },
      "outputs": [],
      "source": [
        "quality  = 9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if codec_name == \"bmshj2018_factorized\":\n",
        "    model      = bmshj2018_factorized(quality=quality, pretrained=True).eval().to(device)\n",
        "    video_code = False\n",
        "    PAD_M      = 64\n",
        "elif codec_name == \"ssf2020\":\n",
        "    model      = ssf2020(quality=quality, pretrained=True).eval().to(device)\n",
        "    video_code = True\n",
        "    PAD_M      = 128         # SSF ↓16, hyper-prior ↑8 → needs /128\n",
        "else:\n",
        "    raise ValueError(f\"Unknown codec {codec_name}\")\n",
        "\n",
        "print(f\"Loaded {codec_name}-Q{quality}  (video={video_code})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkP7ZI8X-UMq",
        "outputId": "9aacf82f-1655-4aac-8d4e-c33a2d58df53"
      },
      "id": "nkP7ZI8X-UMq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ssf2020-Q9  (video=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29dc9811-010f-4fc1-926c-87263cd573d2",
        "id": "h6eWp9BwyOWr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21 sequences:\n",
            " • MOT17-02-DPM\n",
            " • MOT17-02-FRCNN\n",
            " • MOT17-02-SDP\n",
            " • MOT17-04-DPM\n",
            " • MOT17-04-FRCNN\n",
            " • MOT17-04-SDP\n",
            " • MOT17-05-DPM\n",
            " • MOT17-05-FRCNN\n",
            " • MOT17-05-SDP\n",
            " • MOT17-09-DPM\n",
            " • MOT17-09-FRCNN\n",
            " • MOT17-09-SDP\n",
            " • MOT17-10-DPM\n",
            " • MOT17-10-FRCNN\n",
            " • MOT17-10-SDP\n",
            " • MOT17-11-DPM\n",
            " • MOT17-11-FRCNN\n",
            " • MOT17-11-SDP\n",
            " • MOT17-13-DPM\n",
            " • MOT17-13-FRCNN\n",
            " • MOT17-13-SDP\n"
          ]
        }
      ],
      "source": [
        "sequences = [d for d in os.listdir(mot17_root)\n",
        "             if os.path.isdir(os.path.join(mot17_root, d, \"img1\"))]\n",
        "sequences.sort()\n",
        "print(\"Found\", len(sequences), \"sequences:\")\n",
        "for s in sequences: print(\" •\", s)"
      ],
      "id": "h6eWp9BwyOWr"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LVbnsHBfyOWt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "LVbnsHBfyOWt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f993cd-d00d-4ecb-8409-71848c2621dd",
        "id": "fQwnGJ8dyOWt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MOT17-02-DPM ===\n",
            "Frames: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 1080, 1920])) that is different to the input size (torch.Size([1, 3, 1080, 1920])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 1.2291 bpp   |   28.48 dB PSNR\n",
            "\n",
            "=== MOT17-02-FRCNN ===\n",
            "Frames: 15\n",
            "→ 1.2291 bpp   |   31.13 dB PSNR\n",
            "\n",
            "=== MOT17-02-SDP ===\n",
            "Frames: 15\n",
            "→ 1.2291 bpp   |   34.85 dB PSNR\n",
            "\n",
            "=== MOT17-04-DPM ===\n",
            "Frames: 15\n",
            "→ 0.8445 bpp   |   38.70 dB PSNR\n",
            "\n",
            "=== MOT17-04-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.8445 bpp   |   34.61 dB PSNR\n",
            "\n",
            "=== MOT17-04-SDP ===\n",
            "Frames: 15\n",
            "→ 0.8445 bpp   |   36.38 dB PSNR\n",
            "\n",
            "=== MOT17-05-DPM ===\n",
            "Frames: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 480, 640])) that is different to the input size (torch.Size([1, 3, 480, 640])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 1.1990 bpp   |   42.06 dB PSNR\n",
            "\n",
            "=== MOT17-05-FRCNN ===\n",
            "Frames: 16\n",
            "→ 1.1990 bpp   |   42.06 dB PSNR\n",
            "\n",
            "=== MOT17-05-SDP ===\n",
            "Frames: 16\n",
            "→ 1.1990 bpp   |   42.14 dB PSNR\n",
            "\n",
            "=== MOT17-09-DPM ===\n",
            "Frames: 15\n",
            "→ 1.2788 bpp   |   33.11 dB PSNR\n",
            "\n",
            "=== MOT17-09-FRCNN ===\n",
            "Frames: 15\n",
            "→ 1.2788 bpp   |   35.16 dB PSNR\n",
            "\n",
            "=== MOT17-09-SDP ===\n",
            "Frames: 15\n",
            "→ 1.2788 bpp   |   35.31 dB PSNR\n",
            "\n",
            "=== MOT17-10-DPM ===\n",
            "Frames: 16\n",
            "→ 0.7536 bpp   |   42.64 dB PSNR\n",
            "\n",
            "=== MOT17-10-FRCNN ===\n",
            "Frames: 16\n",
            "→ 0.7536 bpp   |   41.12 dB PSNR\n",
            "\n",
            "=== MOT17-10-SDP ===\n",
            "Frames: 16\n",
            "→ 0.7536 bpp   |   34.08 dB PSNR\n",
            "\n",
            "=== MOT17-11-DPM ===\n",
            "Frames: 15\n",
            "→ 0.8594 bpp   |   42.12 dB PSNR\n",
            "\n",
            "=== MOT17-11-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.8594 bpp   |   40.59 dB PSNR\n",
            "\n",
            "=== MOT17-11-SDP ===\n",
            "Frames: 15\n",
            "→ 0.8594 bpp   |   38.14 dB PSNR\n",
            "\n",
            "=== MOT17-13-DPM ===\n",
            "Frames: 15\n",
            "→ 0.7954 bpp   |   30.25 dB PSNR\n",
            "\n",
            "=== MOT17-13-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.7954 bpp   |   34.48 dB PSNR\n",
            "\n",
            "=== MOT17-13-SDP ===\n",
            "Frames: 15\n",
            "→ 0.7954 bpp   |   38.38 dB PSNR\n"
          ]
        }
      ],
      "source": [
        "summary = []          # will collect (seq, frames, bpp, psnr)\n",
        "for seq in sequences:\n",
        "    print(f\"\\n=== {seq} ===\")\n",
        "    img_dir = os.path.join(mot17_root, seq, \"img1\")\n",
        "    out_dir = os.path.join(out_root,   seq)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    out_dir_img1 = os.path.join(out_root, seq, \"img1\")\n",
        "    os.makedirs(out_dir_img1, exist_ok=True)\n",
        "\n",
        "    det_src = os.path.join(mot17_root, seq, \"det\")\n",
        "    det_dst = os.path.join(out_root,   seq, \"det\")\n",
        "    if not os.path.exists(det_dst):\n",
        "        shutil.copytree(det_src, det_dst)\n",
        "    shutil.copy(os.path.join(mot17_root, seq, \"seqinfo.ini\"),\n",
        "                os.path.join(out_root,   seq, \"seqinfo.ini\"))\n",
        "\n",
        "    frame_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
        "                         glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    frame_paths = frame_paths[::len(frame_paths)//15]\n",
        "    n_frames = len(frame_paths)\n",
        "    print(\"Frames:\", n_frames)\n",
        "\n",
        "    total_bits, psnr_sum, n_pixels = 0, 0.0, 0\n",
        "\n",
        "    if video_code:\n",
        "        # ── process in chunks (=GOPs) to control memory\n",
        "        gop = n_frames if GOP_SIZE is None else GOP_SIZE\n",
        "        for g in range(0, n_frames, gop):\n",
        "            end = min(g + gop, n_frames)\n",
        "            clip, orig_hws = [], []\n",
        "            for fp in frame_paths[g:end]:\n",
        "                img = Image.open(fp).convert(\"RGB\")\n",
        "                x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "                clip.append(x); orig_hws.append(hw)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                strings, shapes = model.compress(clip)\n",
        "\n",
        "            # save + metrics\n",
        "            recon = model.decompress(strings, shapes)\n",
        "            for i, (st, sh, hw, x_hat, fp) in enumerate(zip(\n",
        "                    strings, shapes, orig_hws, recon, frame_paths[g:end])):\n",
        "                idx = g + i\n",
        "                # torch.save({\"strings\": st, \"shape\": sh, \"orig_hw\": hw},\n",
        "                #            os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "                total_bits += bits_in(st)\n",
        "\n",
        "                H, W = hw\n",
        "                x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "                x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
        "                mse   = F.mse_loss(x_hat, x_ref)\n",
        "                psnr  = -10 * torch.log10(mse)\n",
        "                psnr_sum += psnr.item()\n",
        "                n_pixels += H * W\n",
        "\n",
        "                rgb8 = (x_hat.squeeze(0).permute(1, 2, 0).clamp_(0, 1).cpu().detach().numpy() * 255).round().astype('uint8')\n",
        "\n",
        "                # write JPEG with MOT naming\n",
        "                cv2.imwrite(os.path.join(out_dir_img1, f\"{idx+1:06d}.jpg\"),\n",
        "                            cv2.cvtColor(rgb8, cv2.COLOR_RGB2BGR),\n",
        "                            [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "\n",
        "            # free GPU mem each GOP\n",
        "            del clip, recon, strings, shapes\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    else:  # ── image codec\n",
        "        for idx, fp in enumerate(tqdm(frame_paths, desc=\"Compressing\")):\n",
        "            img = Image.open(fp).convert(\"RGB\")\n",
        "            x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "            with torch.no_grad():\n",
        "                out = model.compress(x)\n",
        "                x_hat = model.decompress(out[\"strings\"], out[\"shape\"])[0]\n",
        "\n",
        "            torch.save({\"strings\": out[\"strings\"], \"shape\": out[\"shape\"], \"orig_hw\": hw},\n",
        "                       os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "            total_bits += bits_in(out[\"strings\"])\n",
        "\n",
        "            H, W  = hw\n",
        "            x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "            mse   = F.mse_loss(x_hat, to_tensor(img).to(device))\n",
        "            psnr  = -10 * torch.log10(mse)\n",
        "            psnr_sum += psnr.item()\n",
        "            n_pixels += H * W\n",
        "\n",
        "    bpp  = total_bits / n_pixels\n",
        "    psnr = psnr_sum / n_frames\n",
        "    summary.append((seq, n_frames, bpp, psnr))\n",
        "    print(f\"→ {bpp:.4f} bpp   |   {psnr:.2f} dB PSNR\")"
      ],
      "id": "fQwnGJ8dyOWt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceaaf1ae-0e08-44bc-f83a-2567f39255bc",
        "id": "5ZWTILf-yOWt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===========  SUMMARY  ===========\n",
            "Sequence              Frames   BPP     PSNR\n",
            "MOT17-02-DPM              15   1.2291    28.48\n",
            "MOT17-02-FRCNN            15   1.2291    31.13\n",
            "MOT17-02-SDP              15   1.2291    34.85\n",
            "MOT17-04-DPM              15   0.8445    38.70\n",
            "MOT17-04-FRCNN            15   0.8445    34.61\n",
            "MOT17-04-SDP              15   0.8445    36.38\n",
            "MOT17-05-DPM              16   1.1990    42.06\n",
            "MOT17-05-FRCNN            16   1.1990    42.06\n",
            "MOT17-05-SDP              16   1.1990    42.14\n",
            "MOT17-09-DPM              15   1.2788    33.11\n",
            "MOT17-09-FRCNN            15   1.2788    35.16\n",
            "MOT17-09-SDP              15   1.2788    35.31\n",
            "MOT17-10-DPM              16   0.7536    42.64\n",
            "MOT17-10-FRCNN            16   0.7536    41.12\n",
            "MOT17-10-SDP              16   0.7536    34.08\n",
            "MOT17-11-DPM              15   0.8594    42.12\n",
            "MOT17-11-FRCNN            15   0.8594    40.59\n",
            "MOT17-11-SDP              15   0.8594    38.14\n",
            "MOT17-13-DPM              15   0.7954    30.25\n",
            "MOT17-13-FRCNN            15   0.7954    34.48\n",
            "MOT17-13-SDP              15   0.7954    38.38\n",
            "----------------------------------------------\n",
            "Overall                       0.9939    37.01\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n===========  SUMMARY  ===========\")\n",
        "print(f\"{'Sequence':20}  Frames   BPP     PSNR\")\n",
        "for seq, n, bpp, psnr in summary:\n",
        "    print(f\"{seq:20}  {n:6d}   {bpp:5.4f}   {psnr:6.2f}\")\n",
        "overall_bpp  = sum(bpp*n for (_,n,bpp,_) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "overall_psnr = sum(psnr*n for (_,n,_,psnr) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "print(\"----------------------------------------------\")\n",
        "print(f\"{'Overall':20}          {overall_bpp:5.4f}   {overall_psnr:6.2f}\")"
      ],
      "id": "5ZWTILf-yOWt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB2PsIdayOWt"
      },
      "outputs": [],
      "source": [
        "mot17_root = \"BoostTrack/data/MOT17/train\"\n",
        "out_root   = \"BoostTrack/data/MOT17_processed/train\""
      ],
      "id": "pB2PsIdayOWt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c597f214-4187-4e4d-f2ed-85208824b355",
        "id": "cRgnnWHWyOWu"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21 sequences:\n",
            " • MOT17-02-DPM\n",
            " • MOT17-02-FRCNN\n",
            " • MOT17-02-SDP\n",
            " • MOT17-04-DPM\n",
            " • MOT17-04-FRCNN\n",
            " • MOT17-04-SDP\n",
            " • MOT17-05-DPM\n",
            " • MOT17-05-FRCNN\n",
            " • MOT17-05-SDP\n",
            " • MOT17-09-DPM\n",
            " • MOT17-09-FRCNN\n",
            " • MOT17-09-SDP\n",
            " • MOT17-10-DPM\n",
            " • MOT17-10-FRCNN\n",
            " • MOT17-10-SDP\n",
            " • MOT17-11-DPM\n",
            " • MOT17-11-FRCNN\n",
            " • MOT17-11-SDP\n",
            " • MOT17-13-DPM\n",
            " • MOT17-13-FRCNN\n",
            " • MOT17-13-SDP\n"
          ]
        }
      ],
      "source": [
        "sequences = [d for d in os.listdir(mot17_root)\n",
        "             if os.path.isdir(os.path.join(mot17_root, d, \"img1\"))]\n",
        "sequences.sort()\n",
        "print(\"Found\", len(sequences), \"sequences:\")\n",
        "for s in sequences: print(\" •\", s)"
      ],
      "id": "cRgnnWHWyOWu"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "oVr-_PygyOWu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "oVr-_PygyOWu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f565bf8-0140-478d-ed3f-928bec467b7e",
        "id": "UsfEI35TyOWu"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MOT17-02-DPM ===\n",
            "Frames: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 1080, 1920])) that is different to the input size (torch.Size([1, 3, 1080, 1920])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 1.2291 bpp   |   26.53 dB PSNR\n",
            "\n",
            "=== MOT17-02-FRCNN ===\n",
            "Frames: 15\n",
            "→ 1.2291 bpp   |   31.76 dB PSNR\n",
            "\n",
            "=== MOT17-02-SDP ===\n",
            "Frames: 15\n",
            "→ 1.2291 bpp   |   30.92 dB PSNR\n",
            "\n",
            "=== MOT17-04-DPM ===\n",
            "Frames: 15\n",
            "→ 0.8445 bpp   |   36.74 dB PSNR\n",
            "\n",
            "=== MOT17-04-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.8445 bpp   |   37.40 dB PSNR\n",
            "\n",
            "=== MOT17-04-SDP ===\n",
            "Frames: 15\n",
            "→ 0.8445 bpp   |   38.68 dB PSNR\n",
            "\n",
            "=== MOT17-05-DPM ===\n",
            "Frames: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-ff395c20d2f2>:52: UserWarning: Using a target size (torch.Size([3, 480, 640])) that is different to the input size (torch.Size([1, 3, 480, 640])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  mse   = F.mse_loss(x_hat, x_ref)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ 1.1990 bpp   |   40.25 dB PSNR\n",
            "\n",
            "=== MOT17-05-FRCNN ===\n",
            "Frames: 16\n",
            "→ 1.1990 bpp   |   42.14 dB PSNR\n",
            "\n",
            "=== MOT17-05-SDP ===\n",
            "Frames: 16\n",
            "→ 1.1990 bpp   |   43.97 dB PSNR\n",
            "\n",
            "=== MOT17-09-DPM ===\n",
            "Frames: 15\n",
            "→ 1.2788 bpp   |   36.21 dB PSNR\n",
            "\n",
            "=== MOT17-09-FRCNN ===\n",
            "Frames: 15\n",
            "→ 1.2788 bpp   |   39.43 dB PSNR\n",
            "\n",
            "=== MOT17-09-SDP ===\n",
            "Frames: 15\n",
            "→ 1.2788 bpp   |   36.87 dB PSNR\n",
            "\n",
            "=== MOT17-10-DPM ===\n",
            "Frames: 16\n",
            "→ 0.7536 bpp   |   35.04 dB PSNR\n",
            "\n",
            "=== MOT17-10-FRCNN ===\n",
            "Frames: 16\n",
            "→ 0.7536 bpp   |   40.78 dB PSNR\n",
            "\n",
            "=== MOT17-10-SDP ===\n",
            "Frames: 16\n",
            "→ 0.7536 bpp   |   42.68 dB PSNR\n",
            "\n",
            "=== MOT17-11-DPM ===\n",
            "Frames: 15\n",
            "→ 0.8594 bpp   |   38.37 dB PSNR\n",
            "\n",
            "=== MOT17-11-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.8594 bpp   |   35.84 dB PSNR\n",
            "\n",
            "=== MOT17-11-SDP ===\n",
            "Frames: 15\n",
            "→ 0.8594 bpp   |   40.83 dB PSNR\n",
            "\n",
            "=== MOT17-13-DPM ===\n",
            "Frames: 15\n",
            "→ 0.7954 bpp   |   34.28 dB PSNR\n",
            "\n",
            "=== MOT17-13-FRCNN ===\n",
            "Frames: 15\n",
            "→ 0.7954 bpp   |   36.41 dB PSNR\n",
            "\n",
            "=== MOT17-13-SDP ===\n",
            "Frames: 15\n",
            "→ 0.7954 bpp   |   36.50 dB PSNR\n"
          ]
        }
      ],
      "source": [
        "summary = []          # will collect (seq, frames, bpp, psnr)\n",
        "for seq in sequences:\n",
        "    print(f\"\\n=== {seq} ===\")\n",
        "    img_dir = os.path.join(mot17_root, seq, \"img1\")\n",
        "    out_dir = os.path.join(out_root,   seq)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    out_dir_img1 = os.path.join(out_root, seq, \"img1\")\n",
        "    os.makedirs(out_dir_img1, exist_ok=True)\n",
        "\n",
        "    det_src = os.path.join(mot17_root, seq, \"det\")\n",
        "    det_dst = os.path.join(out_root,   seq, \"det\")\n",
        "    if not os.path.exists(det_dst):\n",
        "        shutil.copytree(det_src, det_dst)\n",
        "    shutil.copy(os.path.join(mot17_root, seq, \"seqinfo.ini\"),\n",
        "                os.path.join(out_root,   seq, \"seqinfo.ini\"))\n",
        "\n",
        "    frame_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
        "                         glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    frame_paths = frame_paths[::len(frame_paths)//15]\n",
        "    n_frames = len(frame_paths)\n",
        "    print(\"Frames:\", n_frames)\n",
        "\n",
        "    total_bits, psnr_sum, n_pixels = 0, 0.0, 0\n",
        "\n",
        "    if video_code:\n",
        "        # ── process in chunks (=GOPs) to control memory\n",
        "        gop = n_frames if GOP_SIZE is None else GOP_SIZE\n",
        "        for g in range(0, n_frames, gop):\n",
        "            end = min(g + gop, n_frames)\n",
        "            clip, orig_hws = [], []\n",
        "            for fp in frame_paths[g:end]:\n",
        "                img = Image.open(fp).convert(\"RGB\")\n",
        "                x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "                clip.append(x); orig_hws.append(hw)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                strings, shapes = model.compress(clip)\n",
        "\n",
        "            # save + metrics\n",
        "            recon = model.decompress(strings, shapes)\n",
        "            for i, (st, sh, hw, x_hat, fp) in enumerate(zip(\n",
        "                    strings, shapes, orig_hws, recon, frame_paths[g:end])):\n",
        "                idx = g + i\n",
        "                # torch.save({\"strings\": st, \"shape\": sh, \"orig_hw\": hw},\n",
        "                #            os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "                total_bits += bits_in(st)\n",
        "\n",
        "                H, W = hw\n",
        "                x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "                x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
        "                mse   = F.mse_loss(x_hat, x_ref)\n",
        "                psnr  = -10 * torch.log10(mse)\n",
        "                psnr_sum += psnr.item()\n",
        "                n_pixels += H * W\n",
        "\n",
        "                rgb8 = (x_hat.squeeze(0).permute(1, 2, 0).clamp_(0, 1).cpu().detach().numpy() * 255).round().astype('uint8')\n",
        "\n",
        "                # write JPEG with MOT naming\n",
        "                cv2.imwrite(os.path.join(out_dir_img1, f\"{idx+1:06d}.jpg\"),\n",
        "                            cv2.cvtColor(rgb8, cv2.COLOR_RGB2BGR),\n",
        "                            [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "\n",
        "            # free GPU mem each GOP\n",
        "            del clip, recon, strings, shapes\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    else:  # ── image codec\n",
        "        for idx, fp in enumerate(tqdm(frame_paths, desc=\"Compressing\")):\n",
        "            img = Image.open(fp).convert(\"RGB\")\n",
        "            x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
        "            with torch.no_grad():\n",
        "                out = model.compress(x)\n",
        "                x_hat = model.decompress(out[\"strings\"], out[\"shape\"])[0]\n",
        "\n",
        "            torch.save({\"strings\": out[\"strings\"], \"shape\": out[\"shape\"], \"orig_hw\": hw},\n",
        "                       os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
        "            total_bits += bits_in(out[\"strings\"])\n",
        "\n",
        "            H, W  = hw\n",
        "            x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
        "            mse   = F.mse_loss(x_hat, to_tensor(img).to(device))\n",
        "            psnr  = -10 * torch.log10(mse)\n",
        "            psnr_sum += psnr.item()\n",
        "            n_pixels += H * W\n",
        "\n",
        "    bpp  = total_bits / n_pixels\n",
        "    psnr = psnr_sum / n_frames\n",
        "    summary.append((seq, n_frames, bpp, psnr))\n",
        "    print(f\"→ {bpp:.4f} bpp   |   {psnr:.2f} dB PSNR\")"
      ],
      "id": "UsfEI35TyOWu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud3hIeVqyOWu",
        "outputId": "be02eff0-094d-4d65-8a59-bdb0f4e76e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===========  SUMMARY  ===========\n",
            "Sequence              Frames   BPP     PSNR\n",
            "MOT17-02-DPM              15   1.2291    26.53\n",
            "MOT17-02-FRCNN            15   1.2291    31.76\n",
            "MOT17-02-SDP              15   1.2291    30.92\n",
            "MOT17-04-DPM              15   0.8445    36.74\n",
            "MOT17-04-FRCNN            15   0.8445    37.40\n",
            "MOT17-04-SDP              15   0.8445    38.68\n",
            "MOT17-05-DPM              16   1.1990    40.25\n",
            "MOT17-05-FRCNN            16   1.1990    42.14\n",
            "MOT17-05-SDP              16   1.1990    43.97\n",
            "MOT17-09-DPM              15   1.2788    36.21\n",
            "MOT17-09-FRCNN            15   1.2788    39.43\n",
            "MOT17-09-SDP              15   1.2788    36.87\n",
            "MOT17-10-DPM              16   0.7536    35.04\n",
            "MOT17-10-FRCNN            16   0.7536    40.78\n",
            "MOT17-10-SDP              16   0.7536    42.68\n",
            "MOT17-11-DPM              15   0.8594    38.37\n",
            "MOT17-11-FRCNN            15   0.8594    35.84\n",
            "MOT17-11-SDP              15   0.8594    40.83\n",
            "MOT17-13-DPM              15   0.7954    34.28\n",
            "MOT17-13-FRCNN            15   0.7954    36.41\n",
            "MOT17-13-SDP              15   0.7954    36.50\n",
            "----------------------------------------------\n",
            "Overall                       0.9939    37.29\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n===========  SUMMARY  ===========\")\n",
        "print(f\"{'Sequence':20}  Frames   BPP     PSNR\")\n",
        "for seq, n, bpp, psnr in summary:\n",
        "    print(f\"{seq:20}  {n:6d}   {bpp:5.4f}   {psnr:6.2f}\")\n",
        "overall_bpp  = sum(bpp*n for (_,n,bpp,_) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "overall_psnr = sum(psnr*n for (_,n,_,psnr) in summary) / sum(n for (_,n,_,_) in summary)\n",
        "print(\"----------------------------------------------\")\n",
        "print(f\"{'Overall':20}          {overall_bpp:5.4f}   {overall_psnr:6.2f}\")"
      ],
      "id": "ud3hIeVqyOWu"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:.mlspace-compressai]",
      "language": "python",
      "name": "conda-env-.mlspace-compressai-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}